# -*- coding: utf-8 -*-
"""AI_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iRoTSvg0-GRlkgIsmWACvWRaZW1uk_68
"""

import io
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import time

from google.colab import files
uploaded = files.upload()
df = pd.read_csv(io.BytesIO(uploaded['water_potability.csv']))
# Dataset is now stored in a Pandas Dataframe

"""# **Data Pre Processing:**"""

print(df.isna().sum())

#changing NaNs to means of the feature
df["ph"]=df["ph"].fillna(df["ph"].mean())
df["Sulfate"]=df["Sulfate"].fillna(df["Sulfate"].mean())
df["Trihalomethanes"]=df["Trihalomethanes"].fillna(df["Trihalomethanes"].mean())

#DataFrame Information
print(df, "\n")
print("\n", df.info())

#Getting the proper data into X and it's labels into Y
X = df.drop('Potability', axis=1)
Y = df['Potability']

#Change data into its values (removing headers and row number)
X = X.values
Y = Y.values

"""# **Gaussian Naive Bayes Model Training: and Testing**"""

#start timer
start = time.time()
#set number of folds
kf = KFold(n_splits = (100), shuffle = True)

accuracyAverage = 0
gnb = GaussianNB()
sc = StandardScaler()

actual_classes = np.empty([0], dtype=int)
predicted_classes = np.empty([0], dtype=int)

#train and test for each fold
for train_index, test_index in kf.split(X):
  X_train, X_test = X[train_index], X[test_index]
  Y_train, Y_test = Y[train_index], Y[test_index]
  #Scale X
  X_train = sc.fit_transform(X_train)
  X_test = sc.transform(X_test)

  #fit model
  model=gnb.fit(X_train, Y_train)
  y_pred = model.predict(X_test)

  actual_classes = np.append(actual_classes, Y_test)
  predicted_classes = np.append(predicted_classes, y_pred)
  #get total accuracy per run
  accuracyAverage += accuracy_score(Y_test, y_pred)
  

sorted_labels = ["1","0"]

matrix = confusion_matrix(actual_classes, predicted_classes)
#print the average of the accuracy
print("Accuracy:", accuracyAverage/kf.get_n_splits(X)*100, "%\n")

#stop timer
end = time.time()

#calculate total running time
total_time = end - start
print("Time elapsed: "+ str(total_time), "\n")
#get confusion matrix
plt.figure(figsize=(10,6))
sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap="Blues", fmt="g")
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')

plt.show()

"""# **Time and Accuracy comparison to simple FFNN**"""

import tensorflow as tf
from tensorflow import keras
from keras import metrics
from sklearn.model_selection import train_test_split

#start timer
start = time.time()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, shuffle=True, random_state=0)

#shuffling order of training examples

indices = np.arange(X_train.shape[0])
shuffled_indices = np.random.permutation(indices)

X_train = X_train[shuffled_indices]
Y_train = Y_train[shuffled_indices]

#Scaling X
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#print(X_train.shape)
#print(Y_train.shape)

def build_ffnn_softmax_model(input_shape, n_classes, learning_rate):
    tf.keras.backend.clear_session()
    tf.random.set_seed(0)

    model = keras.Sequential()

    model.add(keras.layers.Flatten(input_shape=input_shape))
    model.add(keras.layers.Dense(units = 80, activation= 'relu'))
    model.add(keras.layers.Dense(
        units = n_classes, activation= 'softmax'
    ))
    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)
    model.compile(loss='sparse_categorical_crossentropy',
                 optimizer = optimizer,
                 metrics = ['accuracy'])
    
    return model


#fit the model 
ffnn_softmax_model = build_ffnn_softmax_model(X_train[0].shape, X_train.shape[1], 0.3)
ffnn_softmax_model.fit(
  x = X_train,
  y = Y_train,
  epochs=10,
  batch_size=64,
  validation_split=0.1,
  verbose=1)
#get predictions
ffnn_softmax_test_predictions = np.argmax(ffnn_softmax_model.predict(X_test), axis=-1)

print("Accuracy: ", accuracy_score(Y_test, ffnn_softmax_test_predictions)*100, "%")

#stop timer
end = time.time()

#calculate total running time
total_time = end - start
print("Time elapsed: "+ str(total_time), "\n")