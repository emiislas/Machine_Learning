# -*- coding: utf-8 -*-
"""Supervised_ML_Workshop_Sp23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18H170p6bSzPXxT2uZNIewMjLoUe66Ut5

Python Imports
"""

import numpy as np #transforms lists into arrays with more manipulation options
import pandas as pd #used for reading files and making them into matrices

"""# **Laplace Naive Bayes**"""

#@title Laplace Naive Bayes Model:
class LaplaceNaiveBayes:
    def __init__(self):
        self.prob_table = []
        self.uniqueWords = []
        self.classes = []
        self.X_train = 0
        self.Y_train = 0

    def laplace_probability(self, X_train, Y_train, currentWord, currentClass):
      #get the number of words in the current class
      total_words_in_class = 0
      #get the number of times the current word appears in the class
      current_word_in_class = 0

      #iterate through or training data to find the total number of words in a class and the 
      for row in range(len(X_train)):
        #if the current row has the label of the current class
        if Y_train[row] == currentClass:
          total_words_in_class += len(X_train[row])
          for col in range(len(X_train[row])):
            if X_train[row][col] == currentWord:
              current_word_in_class += 1

      #laplace smoothing formula
      return (1 + current_word_in_class)/(len(self.uniqueWords) + total_words_in_class)
      
    def fit(self, X_train, Y_train):
      #ignore this, its to use in other methods without calling
      self.X_train = X_train
      self.Y_train = Y_train

      #get all the label types aka classes
      self.classes = np.unique(Y_train)
      #get all the unique words
      self.uniqueWords = np.unique(X_train)
      #make empty probability table of [num of unique words]*[num of classes] in this case 7 * 2
      s = (len(self.uniqueWords), len(self.classes))
      self.prob_table = np.zeros(s)

      #for every unique word check its probability with every class
      for i in range(len(self.uniqueWords)):
        for j in range(len(self.classes)):
          #at the word position we append the probability of the current word to the current class
          self.prob_table[i][j] = self.laplace_probability(X_train, Y_train, self.uniqueWords[i], self.classes[j])
          
      
    def predict(self, X_test):
      #get out probability table and our classes
      prob_table = self.prob_table
      uniqueClasses = self.classes
      #in this array we will append the probability for each class "label"
      classProbabilities = []
      #get the total probability of each class into an array 
      for i in range(len(uniqueClasses)):
          a = np.where(self.Y_train == uniqueClasses[i])
          classProbabilities.append(len(a[0])/len(self.Y_train))

      #uncomment to see the probability of each class
      #print("\n", classProbabilities)

      #here we get the probability of each attribute in the test data for each class and add multiply them into the class probabilities
      for i in range(len(X_test)):
          for j in range(len(prob_table)):
              for k in range(len(uniqueClasses)):
                  if(X_test[i] == self.uniqueWords[j]):
                    classProbabilities[k] *= prob_table[j][k]
            
      #print(classProbabilities) 


      #return the class with the highest probability
      #argmax returns the INDEX with the highest value
      return self.classes[np.argmax(classProbabilities)]

    #method to print our probability table and the words
    def printProbTable(self):
      print(self.classes)
      for i in range(len(self.prob_table)):
          print(self.prob_table[i], self.uniqueWords[i])

"""Fitting and predicting"""

#we initialize our model object
model = LaplaceNaiveBayes()

#We define or obtain our training data
X_train = np.array([["money","gift","money"], 
                    ["money","friend","card"], 
                    ["money","due", "gift"], 
                    ["friend","love","friend"]])

#We define or obtain our labels
Y_train = np.array(["spam", 
                    "spam",
                    "spam", 
                    "nonspam"])

#train our data (fit into model)
model.fit(X_train,Y_train)
#print our probability table
model.printProbTable()
#predict new data
X_test = np.array(["money", "love", "friend", "friend"])
Y_test = model.predict(X_test)
print("\nYour document is!:", Y_test)